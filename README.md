# AURA - AI Unified Response Agent

A production-ready multimodal multi-agent customer support system powered by LLMs and enterprise-grade infrastructure.

## Overview

AURA is an intelligent, multimodal AI system that processes **text, images, and audio** inputs to provide comprehensive customer support. Built with a multi-agent architecture, AURA coordinates specialized AI agents to deliver accurate, context-aware responses while maintaining enterprise-grade scalability and monitoring.

### Why AURA?

- **Multimodal Intelligence**: Seamlessly handles text, image, and audio queries
- **Multi-Agent Orchestration**: Specialized agents work together for optimal results
- **RAG-Powered**: Retrieval-Augmented Generation ensures accurate, contextual responses
- **Enterprise-Ready**: Built with scalable infrastructure and production monitoring
- **Secure & Compliant**: Authentication, audit trails, and data governance built-in
- **Observable**: Real-time monitoring with Grafana and Prometheus

## Features

### Core Capabilities
- Text Agent: Natural language understanding and response generation
- Image Agent: Visual content analysis and interpretation
- Audio Agent: Speech-to-text transcription and audio processing
- Document Processing: PDF, DOCX, and image document parsing
- Vector Search: Semantic retrieval using Pinecone
- Workflow Automation: Apache Airflow for complex task orchestration
- Real-time Messaging: RabbitMQ for inter-agent communication

### User Experience
- Interactive UI: Gradio-based interface for easy interaction
- REST API: FastAPI backend for programmatic access
- Multi-format Upload: Support for various file types
- Real-time Responses: Async processing for fast results

### DevOps & Monitoring
- Docker Support: Containerized deployment
- CI/CD Pipeline: GitHub Actions automation
- Grafana Dashboards: Real-time performance monitoring
- Comprehensive Logging: Track all system activities

## Tech Stack

### AI & Machine Learning
| Component | Technology | Purpose |
|-----------|-----------|---------|
| LLM Framework | LangChain | Agent orchestration and RAG |
| Models | OpenAI GPT, Whisper | Text generation, speech-to-text |
| Embeddings | Sentence Transformers | Document vectorization |
| Computer Vision | OpenCV, PIL | Image processing |

### Infrastructure
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Vector DB | Pinecone | Semantic search and retrieval |
| Database | PostgreSQL (Supabase) | Data persistence |
| Storage | Supabase Storage | Document storage |
| Message Queue | RabbitMQ | Async agent communication |
| Orchestration | Apache Airflow | Workflow management |

### Backend & API
| Component | Technology | Purpose |
|-----------|-----------|---------|
| API Framework | FastAPI | REST API endpoints |
| UI Framework | Gradio | Interactive web interface |
| Auth | OAuth2, JWT | Secure authentication |

### DevOps & Monitoring
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Containerization | Docker | Application packaging |
| CI/CD | GitHub Actions | Automated deployment |
| Monitoring | Prometheus + Grafana | Metrics and visualization |
| Logging | Python Logging | Application logs |

## Prerequisites

Before you begin, ensure you have the following installed:

- Python 3.9+ ([Download](https://www.python.org/downloads/))
- Docker & Docker Compose ([Download](https://www.docker.com/))
- Git ([Download](https://git-scm.com/))

### Required API Keys

You'll need accounts and API keys for:
- [OpenAI](https://platform.openai.com/) - For LLM capabilities
- [Pinecone](https://www.pinecone.io/) - For vector database
- [Supabase](https://supabase.com/) - For storage and database

## Installation

### 1. Clone the Repository

```
git clone https://github.com/deepmehta27/AURA---AI-Unified-Response-Agent.git
cd AURA---AI-Unified-Response-Agent
```

### 2. Create Virtual Environment

```
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

### 3. Install Dependencies

```
pip install -r requirements.txt
```

### 4. Configure Environment Variables

```
# Copy example environment file
cp .env.example .env

# Edit .env file with your API keys
nano .env  # or vim .env, or code .env
```

Required environment variables:
```
OPENAI_API_KEY=your_key_here
PINECONE_API_KEY=your_key_here
PINECONE_ENVIRONMENT=your_env_here
SUPABASE_URL=your_url_here
SUPABASE_KEY=your_key_here
```

### 5. Start Infrastructure Services

```
# Start RabbitMQ, Prometheus, and Grafana
cd docker
docker-compose up -d
cd ..
```

## Usage

### Start the FastAPI Backend

```
cd api
uvicorn main:app --reload --port 8000
```

API will be available at: `http://localhost:8000`

API Documentation: `http://localhost:8000/docs`

### Start the Gradio UI

```
cd ui
python app.py
```

UI will be available at: `http://localhost:7860`

### Access Monitoring Dashboards

- **Grafana**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9090
- **RabbitMQ Management**: http://localhost:15672 (guest/guest)

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                        User Interface                        │
│                   (Gradio UI / FastAPI)                      │
└────────────────┬────────────────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────────────────┐
│                     Agent Orchestrator                      │
│              (Coordinates Agent Activities)                 │
└──────┬──────────────────┬──────────────────┬────────────────┘
       │                  │                  │
       ▼                  ▼                  ▼
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│ Text Agent  │    │Image Agent  │    │Audio Agent  │
│             │    │             │    │             │
│ -  NLP      │    │ -  OCR      │    │ -  STT      │
│ -  QA       │    │ -  Analysis │    │ -  Analysis │
└──────┬──────┘    └──────┬──────┘    └──────┬──────┘
       │                  │                  │
       └──────────────────┴──────────────────┘
                         │
                         ▼
       ┌──────────────────────────────────────┐
       │      RAG Pipeline & Vector Search    │
       │         (Pinecone + LangChain)       │
       └──────────────────────────────────────┘
                         │
        ┌────────────────┼────────────────┐
        ▼                ▼                ▼
┌────────────┐  ┌─────────────┐  ┌──────────────┐
│  Supabase  │  │  RabbitMQ   │  │  PostgreSQL  │
│  Storage   │  │  Messaging  │  │   Database   │
└────────────┘  └─────────────┘  └──────────────┘
```

### Key Components

1. **User Interface Layer**: Gradio UI and FastAPI for user interaction
2. **Agent Orchestration**: Coordinates multiple specialized agents
3. **Processing Agents**: Text, Image, and Audio agents handle specific modalities
4. **RAG Pipeline**: Retrieval-Augmented Generation for accurate responses
5. **Infrastructure**: Pinecone, Supabase, RabbitMQ, PostgreSQL

## Project Structure

```
aura/
├── agents/             # AI agent implementations
├── api/                # FastAPI backend
├── ui/                 # Gradio interface
├── utils/              # Helper utilities
├── models/             # Database models
├── config/             # Configuration files
├── airflow/            # Workflow orchestration
├── monitoring/         # Prometheus metrics
├── docker/             # Docker configurations
├── .github/workflows/  # CI/CD pipelines
└── tests/              # Unit and integration tests
```

## Testing

Run unit tests:

```
pytest tests/ -v
```

## Configuration

Edit `config/config.yaml` to customize:

- LLM model selection
- Agent behavior
- Database connections
- Monitoring settings

## Monitoring

Access monitoring dashboards:

1. **Grafana**: Visualize metrics and create custom dashboards
2. **Prometheus**: Query raw metrics and set up alerts
3. **Application Logs**: Check `logs/` directory for detailed logs

## Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Author

**Deep Mehta**

- GitHub: [@deepmehta27](https://github.com/deepmehta27)
- LinkedIn: [Deep Mehta](https://linkedin.com/in/deepmehta27)
- Email: deepmehta827@gmail.com

## Acknowledgments

- OpenAI for GPT models and Whisper
- Pinecone for vector database
- Supabase for backend infrastructure
- LangChain community for agent frameworks

---

Made with ❤️ by Deep Mehta
```
